Sadrzaj:
* [Hipoteze](#hipoteze)
  * [Parametarske i neparametarske](#parametarske-i-neparametarske)
  * [Proste i slozene](#proste-i-slozene)
* [Tipovi gresaka](#tipovi-gresaka)
* [Uvod u statisticke testove](#uvod-u-statisticke-testove)
  * [Parametarski testovi](#parametarski-testovi)
    * [Studentov t-test](#studentov-t-test)
    * [Nezavisni t-test](#nezavisni-t-test)
    * [Upareni t-test](#upareni-t-test)
  * [Neparametarski testovi](#neparametarski-testovi)
    * [Man-Vitnijev test](#man-vitnijev-test)
    * [Vilkoksonov test](#vilkoksonov-test)

---

# Hipoteze

U literaturi se najcesce javljaju 2 podele hipoteza:
* parametarske i neparametarske
* proste i slozene

## Parametarske i neparametarske

Parametarske se uvek odnose na parametre raspodele. 

Pretpostavlja se da su parametri raspodele onakvi kako se tvrdi.

Primer:  
Normalna raspodela ima parametra, standardnu devijaciju i sredinu.

Parametarska hipoteza mora da se odnosi na neki od parametara. Npr. _sredina populacije je bas vrednost 123_.

Neparametarske se ne odnose na parametre raspodele, vec posmatraju neku karakteristiku raspodele.


Npr. obelezje na nivou populacije ima _eksponencijalnu raspodelu_. Daje se pretpostavka o citavoj raspodeli.

Drugi primer: _medijana na nivou populacije je 50_

Medijana je karakteristika uzorka, ali nije parametar ni jedne raspodele.


## Proste i slozene

**Za $H_{0}$ se uvek bira prosta hipoteza.**

Proste hipoteze jednostavno odredjuju ono sto tvrde.

"Medijana na nivou populacije je 10" tacno odredjuje medijanu te populacije. Pretpostavka je jednoznacna.

Alternativna hipoteza nije prosta jer je suprotna od nulte.

Ako razmotrimo na prethodni primer, alternativna bi bila "medijana na nivou populacije nije 10". Time opisujemo u nekoj meri medijanu, 
ali to nije jednoznacno odredjeno, zbog cega ona nije prosta.

Za $H_{1}$ se obicno uzima slozena hipoteza.

$H_{0}$ je uvek prosta zato sto se mnogo tesko dokazati da je slozena tacna. Npr. "medijana nije 10". 
Postoji mnogo vrednosti za koje je to tacno, a dokazivanje u slucaju kada nemamo jednoznacnost je dosta tesko.

---

Ako je verovatnoca pretpostavke veoma mala (ispod alfa), odbacujemo $H_{0}$ i prihvatamo $H_{1}$. 

Ako je $H_{0}$ proveravao jednakost i dodjemo do toga da trebamo da odbacimo tu pretpostavku, 
to bi znacilo da postoji dovoljno znacajna razlika takva da na populaciji ta pretpostavka 
ne bi vazila. Odnosno, razlika bi bila dovoljno velika toliko da
ne mozemo da prihvatimo tu razliku kao neznacajnu.


Sustina je da se pretpostavi nesto na osnovu uzorka pa ako verovatnoca greske dovoljno velika da se ne moze 
zanemariti onda se odbacuje $H_{0}$ (i time prihvatamo $H_{1}$), a ako je velika toliko da moze da se tolerise, 
prihvatamo $H_{0}$.


# Tipovi gresaka

* [Greska prve vrste - objasnjenje](https://statisticsbyjim.com/hypothesis-testing/type-1-error/)
* [Razlika izmedju greska prve i druge vrste](https://statisticsbyjim.com/hypothesis-testing/types-errors-hypothesis-testing/)

Pri svakom zakljucivanju se pravi greska

* Greska prve vrste: $H_{0}$ tacna, ali je odbacena u testiranju
* Greska druge vrste: $H_{0}$ nije tacna, ali se u testiranju prihvati


Greska prve vrste se naziva **nivo znacajnosti (significance level)** ili **prag znacajnosti testa**.

Ne mozemo kontrolisati obe.

Trudimo da kontrolisemo gresku prve vrste, tj. smatramo da je veca steta ako dolazi 
do takve greske.

Gresku druge vrste koristimo kada su greske prve vrste razlicitih testova jednake. 
Tada je bolji onaj koji ima manju gresku druge vrste.

# Uvod u statisticke testove

Svaki statisticki test sadrzi svoju test statistiku - funkciju koja radi sa uzorkom. 
Za svaki test se zna i raspodela njegove test statistike.

Na osnovu alfa i raspodele test statistike, racuna se **kriticna oblast testa**. 

Za realizovani uzorak se racuna vrednost test statistike. Vrednost za 
test statistike za realizovan uzorak se oznacava tako sto se na oznaku test statistike
doda `*`, npr. $t_{n-1}^\ast$.

Ako vrednost test statistike upadne u kriticnu oblast, ne mozemo da prihvatimo $H_{0}$, vec prihvatamo $H_{1}$.
Granice za kriticne oblasti se odredjuju preko tablice odgovarajuce raspodele.

Ovaj pristup je modifikovan i time je dobijen racunarski metod. Kod njega je dovoljno 
znati samo nultu hipotezu. Taj metod predstavlja koriscenje p-vrednosti i njegovo poredjenje
sa alfom.

Izbor za alfa nekada moze uticati na zakljucak, tako da za jedan izbor prihvatamo jednu 
pretpostavku, a za drugi neku drugu.

Zadatak onoga ko se bavi istrazivanjem je da realne probleme **svede na hipoteze**. 
To je prvi korak. Drugi korak je da se donese odluka oko **dozvoljenog rizika (vrednost za alfa)**.

Izbor nekog od mogucih testova (vezano za prvi korak jer izbor zavisi od hipoteze).

Sledeci korak je dopremanje uzorka. Nakon toga se racuna test statistika, a zatim racunanje 
verovatnoce da se dobije ta vrednost (odredjivanje kriticne oblasti).

Na kraju se donosi odluka prihvatanjem neke pretpostavke.

Parametarski testovi **zahtevaju** normalnu raspodelu.

## Parametarski testovi

Kada su sredine jednake za 2 grupe/merenja, mozemo da kazemo da nema razlike izmedju njih. 
Ako nisu jednako onda je zakljucak da ima razlike. Ovo su bolje reprezentacije zakljucka u 
odnosu na direktno koriscenje prihvacene hipoteze za zakljucak jer je blize krajnjem korisniku 
tog zakljucka.

### Studentov t-test

* [Stepeni slobode](https://sr.wikipedia.org/sr-el/%D0%A1%D1%82%D0%B5%D0%BF%D0%B5%D0%BD%D0%B8_%D1%81%D0%BB%D0%BE%D0%B1%D0%BE%D0%B4%D0%B5_(%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0))

Naziva se jos samo **t-test** ili **t-test za jedan uzorak**, 
a na engleskom: **One-sample t-test**

Parametarski test. 

Testira da li je sredina populacije neki odredjeni broj. U sustini, posmatramo **samo jedno** obelezje 
koje je neprekidno i proveravamo da li ima odredjenu osobinu, tj. odgovarajucu vrednost nekog parametra.

Podrazumeva da obelezje koje analiziramo ima normalnu raspodelu.

Uslovi:
* 1 neprekidno obelezje
* posmatrano obelezje ima normalnu raspodelu

Ima neparametarskog parnjaka, ali necemo da ga spominjemo.

$H_{0}(m=0)$ - sredine su jednake (sredina je jednaka nekoj konkretnoj vrednosti)

gde je $m = m_{1} - m_{2}$

Za alternativu mozemo uzeti: 
* `!=`
* `<` 
* `>`

Uvode se i ove dve za vece i manje kako bi se odredilo gde se nalazi vrednost jer su to 
slozene hipoteze, a nama prosta odgovara jedino trenutno $H_{0}$. Ove opcije za alternativu 
se javljaju i u drugim testovima.

Mozemo isti test da izvrsimo vise puta sa razlicitim alternativnim hipotezama kako bismo 
dosli do konacnog zakljucka.

Test statistika:

$$
t_{n-1} = \frac {\bar{x_{n}} - m_{0}} {\displaystyle\frac {\bar{S_{n}}} {\sqrt{n-1}}} 
= \frac {\bar{x_{n}} - m_{0}} {\displaystyle\frac {\hat{S_{n}}} {\sqrt{n}}} 
$$

$\bar{x_{n}}$ je oznaka za srednju vrednost uzorka.

$m_{0}$ je oznaka za srednju vrednost u odnosu na koju ispitujemo srednju vrednost uzorka. Neka fiksna vrednost.

$\bar{S_{n}}$ je standardna devijacija (uzoracko odstupanje), dok je $\hat{S_{n}}$ 
korigovana (prepravljena) standardna devijacija.

$n$ je obim uzorka.

Ima Studentovu $t$ raspodelu sa $n - 1$ stepenom slobode.

---

Kada kazemo da je alfa `0.05`, podrazumevano da je rec o [`2-tail` vrednosti](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests).

Za Studentovu raspodelu postoje tablice sa izracunatim vrednostima - konstantama.

|  Kriticna oblast                                                   | Alternativna hipoteza |
|:------------------------------------------------------------------:|:---------------------:|
| $C = (- \infty, -t_{n-1, \alpha}) \cup (t_{n-1, \alpha}, +\infty)$ | $H_{1}(m \ne 0)$      |
| $C = (t_{n-1, 2\alpha}, +\infty)$                                  | $H_{1}(m > 0)$        |
| $C = (- \infty, -t_{n-1, 2\alpha})$                                | $H_{1}(m < 0)$        |

Kada prihvatimo alternativnu mozemo dalje da ispitujemo osobine na nivou populacije. 

Postoje 2 nacina:
1. zakljucivanje da vazi na populaciji ono sto vazi na uzorku
   * nije toliko pouzdano, ali moze da se koristi kada je veliki uzorak posto ce tada uzoracka i 
     populaciona sredina da budu blizu
2. izvrsavanje novog testa u kome koristimo drugu alternativnu i zakljucujemo koja od tri 
   alternativne vazi
   * u prvom testu smo odbacili jednu pa nam ostaje u drugom da uradimo isto i time dobijemo konacnu hipotezu

Dvostrani test:
```R
t.test(fost1, mu=42)
```

Pre parametarskog testa proveravamo prvo normalnost raspodele (ako je nema, koristimo neparam.)

Ako hocemo da koristimo neki drugi alternativni test, koristimo `alternative = "less"` 
ili `alternative = "greater"`. Ovo su jednostrani testovi.

`mu` (mi) - aritmeticka sredina

### Nezavisni t-test

* [Varijansa i standardna devijacija](https://e-statistika.rs/varijansa-i-standardna-devijacija)

---

Test koji za jedno obelezje poredi sredine 2 populacije (grupe) koje imaju normalnu raspodelu.

**Neparametarska alternativa**: [Mann-Whitney test (Man-Vitnijev test)](#man-vitnijev-test)

Primer: da li je prosecna platu ista i kod muskaraca ista i kod zena


$m = m_{1} - m_{2}$ 

$H_{0}(m=0)$ - sredine u obe grupe su jednake 

Uslovi:
* **po** 1 neprekidno obelezje iz 2 uzorka/populacije/grupe
* posmatrano obelezje **ima** normalnu raspodelu
* **(opciono, ali pozeljno)** homogenost varijanse

Test statistika:

$$
t = 
\frac 
    {\bar{X_{n_{1}}} - \bar{X_{n_{2}}}}
    {\displaystyle\sqrt {
      \displaystyle\frac {(n_{1}-1)\hat{S_{1}^2} + (n_{2}-1)\hat{S_{2}^2}} {n_{1}+n_{2}-2} 
      \left(\frac {1} {n_{1}} + \frac {1} {n_{2}}\right)
      }
    }
$$

Srednja kvadratna razlika (ocena disperzije) $\bar{S_{n}^2}$ nije stabilna. Spominje se srednja, 
sto znaci da se deli sa `n`. Zbog stabilnosti, umesto `n`, deli se sa `n-1` pa se to zove 
**korigovana uzoracka disperzija** (oznacava se sa  $\hat{S_{n}^2}$).

Ima Studentovu $t$ raspodelu sa $n_{1} + n_{2} - 2$ stepenom slobode.

|  Kriticna oblast                                                   | Alternativna hipoteza |
|:------------------------------------------------------------------:|:---------------------:|
| $C = (- \infty, -t_{n_{1} + n_{2} - 2, \alpha}) \cup (t_{n_{1} + n_{2} - 2, \alpha}, +\infty)$ | $H_{1}(m \ne 0)$      |
| $C = (t_{n_{1} + n_{2} - 2, 2\alpha}, +\infty)$                                  | $H_{1}(m > 0)$        |
| $C = (- \infty, -t_{n_{1} + n_{2} - 2, 2\alpha})$                                | $H_{1}(m < 0)$        |

---


Postoje 2 verzije nezavisnog t-testa, sa jednakim varijantama i bez. Da bismo znali koji 
koristimo, vrsimo Levinov test metodom `leveneTest` iz paketa `car`: 
```R
install.packages("carData")
library(carData)
library(car)
leveneTest(fost1~group)
```

Ovim testom proveravamo da li postoji homogenost varijanse. Rezultat testa nam omogucava
da odredimo koju verziju glavnog testa koristimo.

Njegova $H_{0}$ je: "varijanse su jednake u obe populacije" - $H_{0}(\sigma_{1}^2 = \sigma_{2}^2)$.

Nezavisni t-test sa jednakim varijansama:
```R
t.test(fost1~group, var.equal=TRUE) 
```

`group` je obelezje koje razbija uzorak na grupe, a `fost1` neprekidno obelezje.

### Upareni t-test

Poredi sredine populacije u 2 merenja.

**Neparametarska alternativa**: [Vilkoksonov test](#vilkoksonov-test)

Ideja je da se odradi test, pa da se nesto dogodi (neka akcija) i da se onda testira nakon 
akcije kako bi se video njen efekat (njen uticaj).

Uslovi:
* 2 merenja nad **istom** populacijom
* 1 neprekidno obelezje u oba merenju
* obelezje ima **normalnu raspodelu** u **oba** merenja

Primer: ispitivanje efikasnosti leka


$H_{0}(D=0)$ - sredina u prvom merenju je jednaka sredini u drugom (sredine u merenjima 
su jednake)

$D = m_{1} - m_{2}$ uvedena nova oznaka radi izbegavanja preklapanja oznaka

Test statistika:

$$
t_{n-1} = \frac {\bar{D_{n}}} {\displaystyle\frac {\hat{S_{n}}} {\sqrt{n}}} 
$$

Ima Studentovu $t$ raspodelu sa $n - 1$ stepenom slobode.

|  Kriticna oblast                                                   | Alternativna hipoteza |
|:------------------------------------------------------------------:|:---------------------:|
| $C = (- \infty, -t_{n-1, \alpha}) \cup (t_{n-1, \alpha}, +\infty)$ | $H_{1}(D \ne 0)$      |
| $C = (t_{n-1, 2\alpha}, +\infty)$                                  | $H_{1}(D > 0)$        |
| $C = (- \infty, -t_{n-1, 2\alpha})$                                | $H_{1}(D < 0)$        |

```R
t.test(fost1, fost2, paired = TRUE)
```


## Neparametarski testovi

Mean smo birali kao test statistiku kod parametarskih jer zbog normalnosti imaju u sredini 
najcesce vrednosti. Zbog toga u neparametarskim testovima koristimo
medijanu jer je u odnosu na nju jedna polovina vrednosti manja, a 
druga veca.

Sredinu mogu da povuku velike vrednosti pa da time poniste uticaj veceg broja malih vrednosti.

Svi neparametarski testovi koriste rang umesto realnih vrednosti.

Mogu da se koriste umesto parametarskih, ali to nije preporucljivo jer je parametarski 
precizniji (neparametarski nisu dovoljno tacni).


Smer razlike moze da se odredi:
1. pomocu medijane u uzorku
2. jednosmernim testom 

### Man-Vitnijev test

* https://www.statology.org/mann-whitney-u-test

---

engl. **Mann-Whitney test**

$H_{0}(M=0)$ - nema razlike izmedju medijana

$M = M_{1} - M_{2}$, gde $M_{1}$ medijana prve grupe, a $M_{2}$ druge.

Uslovi:
* **po** 1 neprekidno obelezje iz 2 uzorka/populacije/grupe

Uzorci **ne moraju** da imaju isti obim. Prvo se spajaju u jednu celinu, a zatim rangiraju. 

Na kraju se sabiraju **rangovi** (pozicije) elemenata uzorka **manjeg** obima.

Ako su istog obima, onda se uzima onaj sa **manjom sumom** rangova.

Proces je dalje isti kao i za parametarske testove.

Test statistika:

$$
T_{n_{1}} = \displaystyle\sum_{k=1}^{n_1} r_{x_{k}}
$$

gde je $(x_{1}, x_{2}, \dots,  x_{n_{1}})$ uzorak koji ima **manji obim**, 
$n_{1}$ njegov obim, a $r_{k}$ rang `k`. clana tog uzorka. Radi 
jednostavnosti se bira da se sa `1` oznaci taj uzorak.

|  Kriticna oblast                                                 | Alternativna hipoteza |
|:----------------------------------------------------------------:|:---------------------:|
| $C = (0, T_{n_{1}, n_{2}}^a) \cup (T_{n_{1}, n_{2}}^b, +\infty)$ | $H_{1}(M \ne 0)$      |


Primer:
```
uzorak1 = {a,d}
uzorak2 = {b,c,e}

celina = {a,b,c,d,e}
rangiranje = {a:1, b:2, c:3, d:4, e:5}

test_stat = ranjgiranje[a] + ranjgiranje[d] = 1 + 4 = 5

n1 = kardinalnost(uzorak1) = 2
n2 = kardinalnost(uzorak2) = 3

Vrednost granice u kriticnoj oblasti za kardinalnosti datih uzoraka
(n1 i n2) citamo iz tabele.
```

### Vilkoksonov test


* https://www.statology.org/wilcoxon-signed-rank-test
    * **Napomena**: za igrace 1, 8, 10, 11 i 15 je `3` zato sto 
      je to vrednost proseka njihovih pozicija u varijacionom nizu, tj.
      `suma = 3+4+5+6+7 = 15`, `n = 5`, pa je `rank = suma/n = 15/5 = 3`

engl. **Wilcoxon t-test** ili **Wilcoxon signed-rank test**

Vilkoksonov test:
1. rangiranje apsolutnih vrednosti razlika
2. rangu se dodeljuje znak razlike
3. sabiranje pozitivnih / negativnih rangova
4. test statistika: $\min\left(\sum{\text{pozitivni rangovi}} \;  \left| \sum{\text{negativni rangovi}} \right| \right)$
5. granice za kriticni region se citaju iz tablice koja je predvidjena za ovaj test
6. prihvatanje neke hipoteze



$H_{0}(M=0)$ - medijane su po merenjima jednake

Nekada nam je potrebno da napravimo dataframe kako bi se uskladili sa sintaksom za razbijanje:
```R
dat2 <- data.frame(
  Moment = c(rep("Before", 44), rep("After", 44)),
  Glukoza = c(Glukoza$Before, Glukoza$After)
)
dat2
```

Metod `rep(x, y)`  ponavlja `x` vrednost `y` puta. 

Za ovaj test koristimo funkciju `wilcox.test` iz paketa `stats`:	
```R
wilcox.test(dat2$Glukoza~dat2$Moment, paired=TRUE)
```