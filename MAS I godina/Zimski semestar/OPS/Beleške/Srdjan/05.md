Sadrzaj:
* [Regresioni model](#regresioni-model)
* [Korelacija](#korelacija)
  * [Pitersonov koeficijent korelacije](#pitersonov-koeficijent-korelacije)
    * [Test](#test)
    * [Klasifikacije inteziteta korelacije](#klasifikacije-inteziteta-korelacije)
  * [Spirmanov koeficijent korelacije](#spirmanov-koeficijent-korelacije)
    * [Test](#test-1)


# Regresioni model

Ideja je da se linearnom jednacinom, pomocu poznatnog obelezja, predvidi nepoznatno obelezje.

Moze se raditi u svakoj situaciji, ali to nema uvek smisla.

Pravi se kada postoji veza izmedju y i x.

Ako postoji zajednicko usmerenje (ponasanje), onda ima smisla predvidjati jedno obelezje preko drugog.

Kod linearnog modela imamo konstante a i b. Njih mozemo izracunati za svaki skup koji sadrzi podatke x i y.
Medjutim, nema smisla praviti model za predikciju ako se predikcija ne moze izvrsiti posto ne postoji zavisnost.

# Korelacija

**Korelacijom** ispitujemo da li postoji zavisnost izmedju x i y, pa ako postoji onda pravimo model koji 
je opisuje.

Veza ne mora da se opise linearnom funkcijom. To moze biti i drugi tip funkcije.

Prvi naucnici koji su se bavili korelacijom su Gauton i Pirson.

Pirson je uveo pojam koeficijenta linearne korelacije. Njegova mana je to sto moze da detektuje samo
linearnu korelaciju. Ukoliko postoji neki drugi oblik korelacije, ponasa se kao da nema korelacije.

Neki drugi pristupi mogu u nekoj meri da detektuju nelinearne zavisnosti.

Pirsonov koeficijent mozemo da koristimo pri ispitivanju postojanja korelacije radi kreiranja
linearnog regresivnog modela.

Korelacija je **povezanost**, a ne zavisnost!

Zavisnost izmedju 2 obelezja predstavlja vezu u kojoj promena jednog dovodi do promene drugog obelezja. Imamo
neku vrstu uzrocno-posledicnog odnosa.

Korelacijom proveravamo da li se ta dva obelezja ponasaju isto.

Kod zavisnosti imamo zavisno i nezavisno obelezje. Zavisno obelezje zavisi od nezavisnog, sto znaci da ce
promene nezavisnog uticati na zavisno. Obrnuto ne vazi, zbog cega i kazemo da je to neko obelezje nezavisno.

Polazna tacka za ispitivanje korelacije je scatter dijagram. Preko njega ne mozemo da zakljucimo da postoji,
ali mozemo da ga iskoristimo kako bismo videli da li postoji mogucnost za postojanje korelacije.

Maksimalna vrednost za korelaciju je `1`, ako je rec o poziticnoj korelaciji, ili `-1` ako je rec o negativnoj 
korelaciji.

Pozitivna opisuje slucaj kada sa porastom vrednosti jednog obelezja, dolazi i do porasta vrednosti drugogo obelezja.
Kod negativne korelacije je suprotno, sa porastom jednog dolazi do smanjenja drugog.

Minimalna vrednost za korelaciju je `0`.

Podaci mogu i da budu rasporedjeni tako da se kroz njih moze provuci neka **kriva** linija koja ih aproksimira. 
Tu korelaciju ne mozemo detektovati Pirsonovim koeficijentom, kao sto smo prethodno i spomenuli.

---

Korelacija moze da se odredjuje samo izmedju 2 obelezja. Ako ih ima vise, vrsi se poredjenje izmedju parova
(kombinacija).

Broj parova za $n$ obelezja (ne mora da se uci, moze i da se izvede):

$$
C_{2}^n = \frac {n!} {2 \cdot (n-2)!} = \frac {n \cdot (n-1)} {2}
$$

## Pitersonov koeficijent korelacije

Slucajne promenljive - termin iz verovatnoce

Obelezje - termin u statistici


Koeficijent korelacije izmedju 2 slucajne promenljive.

Za teorijsko izracunavanje korelacije, onako kako je to Pirson racunao, neopodan je **z-score**.

Z-score se racuna za **svaki element** uzorka (za razliku od sredine npr. koja se racuna jednom za celu populaciju).

$$
Z\text{-}score = \frac {x - \bar{x}} {\bar{S_{n}}}
$$

Znak za z-score nam pokazuje da li je element levo ili desno u odnosu na sredinu.

Ono sto je bitnija informacija jeste to koliko devijacija element odstupa od aritmeticke sredine.

Z-score se koristi kada se uporedjuju velicine na razlicitim skalama kako bi se one ujednacile.

Primer: 
Kosarka i fudbal imaju razlicite skale za poene. Na prvi pogled moze da izgleda da je kosarka produktivnija zbog
veceh broja poena, ali nakon prilagodjavanja sa z-score, moze se dogoditi da je neka fudbalska liga ipak produktivnija
od neke kosarkaske lige.

---

Kako radi z-score?

Pretpostavimo da imamo jaku pozitivnu korelaciju izmedju obelezja A i B. Ako A uzima velike vrednosti, to bi znacilo 
da su one udaljene od sredine. Tada i z-score ima veliku vrednost jer se posmatra u odnosu na sredinu.

S obzirom da imamo korelaciju, i kod obelezje B bi doslo do promene vrednosti. I kod njega bi z-score bio veliki.

Kada oduzmemo z-score obelezja A i z-score obelezja B, dobili bi kao rezultat nesto blisko nuli.

Da smo imali negativnu korelaciju, sa porastom A doslo bi do smanjenja B. Tada bi A bilo mnogo veliko, pa bi i z-score
njegov bio veliki, a B bi bilo sve udaljenije od sredine, ali u drugu stranu pa bi njegov z-score bio negativan.

Oduzimanjem vrednosti za z-score obelezja A sa vrednoscu za z-score obelezja B, dobijamo da kao rezultat 2 * z-score (minus i minus daju plus).

---

Prva ideja za izracunavanje korelacija jeste da se ona moze izracunati kao prosek svih razlika svih vrednosti za z-score. Posto vrednosti 
mogu biti i negativne, razlika se kvadrira.

Takodje, potrebna je i korekcija pa se koristi `n-1`.

Formula:

$$
r = \frac {\sum \left(z\text{-}score_{A} - z\text{-}score_{B} \right)^{2} } {n-1}
$$

Ono sto nije odgovaralo sa ovakvom formulom jeste to sto je opseg vrednosti izmedju `0` i `4`, sto je nezgodno za tumacenje podataka.

Jednostavnije je da bude izmedju `-1` i `1`, gde negativne vrednosti predstavljaju jacinu za negativnu korelaciju, a pozitivne za
pozitivnu.

Konacna formula za Pirsonov koeficijent korelacije:

$$
r = 1 - \frac {1} {2} \cdot \frac {\sum \left(z\text{-}score_{A} - z\text{-}score_{B} \right)^{2} } {n-1}
$$


Ono sto se moze primetiti iz formule jeste da **nije bitan redosled** izmedju obelezja.


Ovakav koef. korelacije je **osetljiv** na netipicne tacke, sto je jos jedna od mana Pirsonovog testa.

To je problem svake parametarske tehnike jer se izvode direktno iz podataka (tj. ne vrse neku transformaciju kao sto se to radi sa rankovima).

---

Ljudi koji se ne bave matematikom, cesto lose tumace koeficijent korelacije. Stice se utisak da koef. korelacije od `0.7` kaze
da mozemo napraviti model koji opisuje `70%` ispitanika, tj. da se obelezje B za `70%` ispitanika moze objasniti preko
obelezja A, sto **nije tacno!**  

Ono sto se na osnovu te vrednosti moze zakljuciti jeste da korelacija postoji i da je jaka. Ima smisla praviti model, ali
to ne opisuje uspesnost tog modela.

**Koeficijent determinacije**, u oznaci $r^2$, opisuje koji procenat varijanse zavisnog obelezja moze da se opise preko nezavisnog obelezja.

Tj. koji procenat `y` (zavisno) moze da se opise preko `x` (nezavisno). 

On takodje ne moze da se tumaci kao procenat uspesnosti samog modela.

Govori o tome koji procenat promene `y` moze da se opise preko `x`. Ako bi do bilo `65%`, to bi znacilo da toliki udeo `x` ima u promeni `y`, 
dok je preostalih `35%` uticaj nekih drugih faktora.

---

Postoji i druga formula za Pirsonov koeficijent koja nam omogucava da ga racunamo direktno iz podataka, sto nismo mogli sa prvom
posto je prvo bilo potrebno izracunati z-score za svako x i y, da se pomnoze a onda uprosece.

Najlaksa formula za pamcenje:

$$
r = \displaystyle\frac {\displaystyle \sum_{k=1}^n (x_{k}  - \bar{x}) \cdot (y_{k}  - \bar{y}) } {\displaystyle \sqrt {\sum_{k=1}^n (x_{k} - \bar{x})^2 \cdot \sum_{k=1}^n (y_{k} - \bar{y})^2}}
$$

### Test

Korelacija se dobija iz uzorka. To znaci da ne mozemo odmah zakljucak o korelaciji primeniti na populaciju.

Sada trebamo utvrditi da li ono sto vazi i na uzorku, vazi i na populaciji.

Kako prenosimo rezultat sa uzorka na populaciju?

To utvrdjujemo statistickim testovima.

Uvodimo test koji ima hipoteze:

$$
H_{0}(r=0) \\

H_{1}(r \ne 0)
$$

$H_{0}$ kaze "koeficijent korelacije na nivou populacije je 0".

Ako se prihvati $H_{0}$, to znaci da nemamo korelaciju na populaciji, iako ona mozda postoji na uzorku.

Tek kada se prihvati $H_{1}$, moze se diskutovati o jacini korelacije.

Test ima vecu znacajnost "od broja".

Test statistika:

$$
t_{n-2} = \frac {r} {\sqrt {1 - r^2}} \sqrt {n-2}
$$

Ovde treba primetiti da u formuli figurise obim uzorka. To nam ukazuje da obim uzorka ima znacajnu ulogu u ovom testu.

$t_{n-2}$ ima Studentovu t-raspodelu sa stepenom slobode $n-2$, sto znaci da nam je neophodna tablica za Studentovu t-raspodelu.

Zavisno od odabrana alternativne hipoteze, koriste se sledece kriticne oblasti:
|  Kriticna oblast         | Alternativna hipoteza |
|:--------------------------------------------------------------------------:|:-----------------:|
| $ C = (- \infty, -t_{n-2, \alpha}) \cup (t_{n-2, \alpha}, +\infty) $ | $H_{1}(r \ne 0) $ |
| $ C = (t_{n-2, 2\alpha}, +\infty) $ | $H_{1}(r > 0) $ |
| $ C = (- \infty, -t_{n-2, 2\alpha}) $ | $H_{1}(r < 0) $ |

U praksi se prvo izracuna koeficijent korelacije, pa se vrsi test, ali teorijsi gledano, prvo se diskutuje o testu, a zatim se
analizira dobijena vrednost.

Parametarske tehnike se prave tako da se racunaju direktno iz podataka. Kod njih se obicno racuna sa realnim podacima, zbog cega
i jesu preciznije od neparametarskih. 

Neparametarski nisu dovoljno tacni jer se informacija preradi i izgubi.

Posto Pirsonov test koristi realne podatke, on se klasifikuje u parametarske tehnike.

Uslovi za Pirsonov test:
* oba neprekidna obeleza
  * teorijski zahtev; u praksi je dovoljno da barem 1 ima

---

Za dobijanje vrednosti za Pirsonov koeficijent korelacije, koristimo funkciju `cor` iz paketa `stats`:
```R
cor(a, b)
```

Tek kada se utvrdi da postoji korelacija, tumacimo dobijenu vrednost za koeficijent korelacije
(smer i jacina korelacije).

Sto je veca korelacija, to ce model za predikciju imati bolju procenu.

---

Za Pirsonov test znacajnosti za koeficijent korelacije koristimo funkciju `cor.test` iz paketa `stats`:
```R
cor.test(a, b)
```

Za zaokruzivanje ove vrednost na 2 decimale mozemo koristi: `round(val, 2)`.


Ukoliko zelimo da ga izvrsimo za sva obelezja u bazi, koristimo funkciju `correlation` iz paketa `correlation`
(neophodan je i paket `psych`):
```R
install.packages("correlation")
install.packages("psych")

library("correlation")
library("psych")

Data <- data.frame(fost1, confid1, depress1, exam)
correlation::correlation(Data, include_factors = TRUE, method = "auto")
```

Zbog toga sto vrsi proveru za sva obelezja i pritom zahteva bazu, izdvajamo podatke u novu bazu i onda nju prosledjujemo.

### Klasifikacije inteziteta korelacije

Ima ih mnogo. Koristicemo Kojinovu skalu:
|  Opseg                       | Klasifikacija |
|:----------------------------:|:-----------:|
| &#124;r&#124; < 0.2          | veoma slaba |
| 0.2 &le; &#124;r&#124; < 0.4 | slaba |
| 0.4 &le; &#124;r&#124; < 0.6 | srednjeg inteziteta |
| 0.6 &le; &#124;r&#124; < 0.8 | jaka |
| &#124;r&#124; &ge; 0.8       | veoma jaka |


## Spirmanov koeficijent korelacije

Predstavlja **neparametarsku** alternativu za Pirsonov koeficijent korelacije.

Pirsonov koef. korelacije se ne koristi jer nemamo normalnu raspodelu, tj. veliki broj vrednosti koje su bliske 
aritmetickoj sredini, pa ce postojati mogucnost za stvaranje velikog broja outlier-a. Outlier-i u velikoj meri 
uticu na tacnost parametarskih tehnika.

**Spirmanov koeficijent korelacije je Pirsonov koeficijent korelacije u kome koristimo rangove umesto izmerenih vrednosti.**

U ovoj tehnici **ne vrsimo na isti nacin** rangiranje kao u prethodnim tehnikama koje su koristile rangiranje. Umesto 
rangiranja svih vrednosti u uzorku, mi rangiramo vrednosti posebno za svako obelezje.

Kod tih tehnika se vrsilo sumiranje, a zatim birala  suma manjeg uzorka.

Kod odredjivanja Spirmanovog koeficijenta se posebno rangira `x`, a posebno `y`.

Formula za Spirmanov koeficijent korelacije:

$$
\rho_{X,Y} = 1 - \displaystyle\frac {6 \displaystyle\sum_{i=1}^n {d_{i}^2}} {n (n^2 - 1)}
$$

gde je ${d_{i} = rang(x_{i}) - rang(y_{i})}$

Rangovi mozda nisu prave vrednosti, ali ipak mogu da opisu korelaciju koja se javlja u podacima.

Velika vrednost ce biti predstavljena nekom krajnjom pozicijom u varijacionog nizu, tj. visokim rangom, i obrnuto za
male vrednosti.

Spirmanov koeficijent zadrzava dosta dobrih osobina koje poseduje Pirsonov koeficijent:
* simetrican je (nije bitno kako se uporedjuju obelezja, tj. da li se trazi za `x y` ili `y x`)
* opseg izmedju `-1` i `1`

Velika prednost u odnosu na Pirsonov koeficijent je to sto nije toliko osetljiv na netipicne vrednosti. Zasto? 
Zato sto to ne utice na rang posto on zavisi od pozicije u varijacionom nizu. Koliko god da je velika vrednost, 
rang moze najvise da bude onoliki koliko imamo elemenata. Ta vrednost bi bila poslednja u sortiranom (varijacionom) 
nizu pa koliko god da povecavamo vrednost, ona ce uvek ostati na istom rangu.

Moze da prepozna **nelinearnu korelaciju**, za razliku od Pirsonovog koeficijenta. Nije dovoljno precizan za zakljucivanje
i dokazivanje, ali moze da postoji nekakva korelacija, tj. da je detektuje.


S obzirom da je korelacija izracunata na osnovu uzorka, potrebno je i kod ove tehnike da se ispita vazenje tog zakljucka
na populaciji upotrebnom statistickih testova.

---

Kada su rangovi blizu jedan drugom, mozemo **naslutiti** vec da postoji neka korelacija. Ako pogledamo formulu, to 
mozemo i primetiti. $d_{i}$ je njihova razlika, a posto su slicni, to bi bila mala vrednost. Njihova suma bi takodje
bila nema veoma mala vrednost bliska nuli, pa mi nakon deljenja imali takodje neku veoma malu vrednost. Jedinica minus
tako mala vrednost na kraju daje vrednost pribliznu jedinici, sto znaci da ima korelacije.

### Test

Nulta hipoteza - "Nema korelacije na nivou populacije"

$$
H_{0}(\rho=0) \\
$$

Alternativna:

$$
H_{1}(r \ne 0) \\
ili \\
H_{1}(\rho < 0) \\
ili \\
H_{1}(\rho > 0) \\
$$

Svaka alternativna hipoteza ima svoj kriticki region (kriticnu oblast):
| Kriticna oblast                                                      | Alternativna hipoteza |
|:--------------------------------------------------------------------:|:---------------------:|
| $ C = (- \infty, -t_{n-2, \alpha}) \cup (t_{n-2, \alpha}, +\infty) $ | $H_{1}(\rho \ne 0) $  |
| $ C = (t_{n-2, 2\alpha}, +\infty) $                                  | $H_{1}(\rho > 0) $    |
| $ C = (- \infty, -t_{n-2, 2\alpha}) $                                | $H_{1}(\rho < 0) $    |

$t_{n-2}$ ima Studentovu t-raspodelu sa stepenom slobode $n-2$.

---

Za Spirmanov test znacajnosti za koeficijent korelacije koristimo funkciju `cor.test` iz paketa `stats`:
```R
cor.test(a, b, method = "spearman")
```

Razlika u odnosu na kod za Pirsonov test jeste samo to sto navodimo argument `method`.

Slicno je i sa vrsenjem ispitivanja korelacije kada imamo vise obelezja, tj. kada zelimo da to odradimo
nad celom bazom:
```R
install.packages("correlation")
install.packages("psych")

library("correlation")
library("psych")

Data1 <- data.frame(age, alchohol, hourwnit, weight)
correlation::correlation(Data1, include_factors = TRUE, method = "spearman")
```

## Izbor testa za korelaciju

Pretpostavimo da imamo 4 obelezja. Neophodno je da izmedju parova koji predstavljaju njihove 
kombinacije izvrsimo test korelacije.

Ako jedno medju njima nema normalnu raspodelu, biramo Pirsonov test znacajnosti. Mozemo da ga koristimo
jer smo spomenuli da je u praksi dovoljno da jedno od dva obelezja koja se porede ima normalnu raspodelu.

Ukoliko bi ih bilo vise, onda bismo za parove u kojima oba obelezja nemaju normalnu raspodelu koristili
Spirmanov test znacajnosti, a u onima u kojima jedno ili dva obelezja imaju, koristili Pirsonov test.

Jos jedna od mogucnosti je da samo jedno obelezje ima normalnu raspodelu, a da sva ostala nemaju. Tu tom slucaju
bismo koristili Pirsonov test za parove ciji je clan ovo obelezje, dok bi za ostale parove u kojima nije clan
radili Spirmanov test.